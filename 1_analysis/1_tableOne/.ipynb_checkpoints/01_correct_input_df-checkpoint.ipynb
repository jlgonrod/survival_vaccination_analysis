{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Libraries and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_dataframe = True # Numerical variables imputed or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from each hospital unit. The data is available in both CSV and pickle formats, with or without imputation for numerical variables. Imputed dataframe will be used in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01_correct_input_df-checkpoint.ipynb']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../0_get_data/data/out/patient_imputed.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/juanluisgonzalez/FPS_proyects/Vacc_analisys/1_analysis/1_tableOne/.ipynb_checkpoints/01_correct_input_df-checkpoint.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanluisgonzalez/FPS_proyects/Vacc_analisys/1_analysis/1_tableOne/.ipynb_checkpoints/01_correct_input_df-checkpoint.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39mlistdir())\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanluisgonzalez/FPS_proyects/Vacc_analisys/1_analysis/1_tableOne/.ipynb_checkpoints/01_correct_input_df-checkpoint.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Load the pickle dataframe and reset index\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juanluisgonzalez/FPS_proyects/Vacc_analisys/1_analysis/1_tableOne/.ipynb_checkpoints/01_correct_input_df-checkpoint.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(path)\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m#TODO PONER PATH CORRECTO\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juanluisgonzalez/FPS_proyects/Vacc_analisys/1_analysis/1_tableOne/.ipynb_checkpoints/01_correct_input_df-checkpoint.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39minfo())\n",
      "File \u001b[0;32m~/FPS_proyects/Vacc_analisys/.venv/lib64/python3.9/site-packages/pandas/io/pickle.py:179\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[0;32m--> 179\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    180\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    181\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    182\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    183\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    184\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    185\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    186\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    192\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/FPS_proyects/Vacc_analisys/.venv/lib64/python3.9/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    869\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../0_get_data/data/out/patient_imputed.pkl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Get the path of imputed/not imputed data\n",
    "path = \"../../0_get_data/data/out/\"\n",
    "if imputed_dataframe:\n",
    "    path += \"patient_imputed.pkl\"\n",
    "else:\n",
    "    path += \"patient.pkl\"\n",
    "print(os.listdir())\n",
    "# Load the pickle dataframe and reset index\n",
    "df = pd.read_pickle(path).reset_index(drop=True) #TODO PONER PATH CORRECTO\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform minor correctios to df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapper (\"old_name\": \"new_name\")\n",
    "new_col_names = {\"COD_FEC_FALLECIMIENTO\": \"death_datetime\",\n",
    "                 \"NUHSA_ENCRIPTADO\": \"id\",\n",
    "                 \"centro\": \"center\",\n",
    "                 \"uci\": \"icu\",\n",
    "                 \"provincia\": \"province\",\n",
    "                 \"periodo_1\": \"wave_1\",\n",
    "                 \"periodo_2\": \"wave_2\",\n",
    "                 \"periodo_3\": \"wave_3\",\n",
    "                 \"periodo_4\": \"wave_4\",\n",
    "                 \"periodo_5\": \"wave_5\",\n",
    "                 \"periodo_6\": \"wave_6\",\n",
    "                 \"periodo_7\": \"wave_7\"\n",
    "                 }\n",
    "\n",
    "# perform the rename\n",
    "df.rename(columns=new_col_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first record in which the admitted patient is vaccinated is the one indicated in the output of the next cell, records from pandemic periods in which there were no vaccinations available will be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_vacc = pd.read_pickle(\"../../0_get_data/data/vacunas.pkl\")[\"FEC_VACUNACION\"].sort_values().reset_index().iloc[0][\"FEC_VACUNACION\"]\n",
    "print(\"first vaccunation in the dataset:\", first_vacc.strftime('%d/%m/%Y'))\n",
    "\n",
    "waves_dates = pd.read_csv(\"../../0_get_data/data/05_Periodos_pandemicos.csv\", sep=\";\")\n",
    "waves_dates[\"fecha_inicio\"] = pd.to_datetime(waves_dates[\"fecha_inicio\"])\n",
    "waves_dates[\"fecha_fin\"] = pd.to_datetime(waves_dates[\"fecha_fin\"])\n",
    "# Create a dictionary to map periods to waves\n",
    "period_to_wave = {\n",
    "    \"Periodo 1\": \"wave_1\",\n",
    "    \"Periodo 2\": \"wave_2\",\n",
    "    \"Periodo 3\": \"wave_3\",\n",
    "    \"Periodo 4\": \"wave_4\",\n",
    "    \"Periodo 5\": \"wave_5\",\n",
    "    \"Periodo 6\": \"wave_6\",\n",
    "    \"Periodo 7\": \"wave_7\"\n",
    "}\n",
    "\n",
    "# Apply the dictionary to the 'nombre_periodo' column\n",
    "waves_dates['nombre_periodo'] = waves_dates['nombre_periodo'].apply(lambda period: period_to_wave.get(period))\n",
    "\n",
    "waves_dates['vacc_available'] = waves_dates[\"fecha_fin\"] >= first_vacc\n",
    "\n",
    "waves_drop = waves_dates[waves_dates[\"vacc_available\"]==False][\"nombre_periodo\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wave_i in waves_drop:\n",
    "    index_to_drop = df[df[wave_i]==1].index\n",
    "    print(f\"Rows removed from {wave_i}: {len(index_to_drop)}\")\n",
    "    df.drop(index_to_drop, inplace=True)\n",
    "    df.drop(columns=wave_i, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_var_order = [\"id\",\n",
    "                     \"sex\",\n",
    "                     \"age\",\n",
    "                     \"center\",\n",
    "                     \"type_center\",\n",
    "                     \"num_shots\", \n",
    "                     \"icu\", \n",
    "                     \"province\", \n",
    "                     \"reinfected\",\n",
    "                     \"inpatient_days\",                 \n",
    "                     \"admission_datetime\",\n",
    "                     \"discharge_datetime\", \n",
    "                     \"hospital_outcome\",\n",
    "                     \"death_datetime\",\n",
    "                     \"delta_days_death\"\n",
    "                     ]\n",
    "\n",
    "waves_cols =  sorted([col for col in df.columns if col.startswith('wave')])\n",
    "pmhx_cols = sorted([col for col in df.columns if col.startswith('pmhx')])\n",
    "lab_cols = sorted([col for col in df.columns if col.startswith('lab')])\n",
    "\n",
    "# Define the desired order\n",
    "desired_orders = general_var_order + waves_cols + pmhx_cols + lab_cols\n",
    "\n",
    "# Perform the order\n",
    "df = df[desired_orders]\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the type of variables to change\n",
    "mapper = {\"sex\": \"category\",\n",
    "          \"center\": \"category\",\n",
    "          \"icu\": \"category\",\n",
    "          \"province\": \"category\",\n",
    "          \"hospital_outcome\": \"category\",\n",
    "          \"delta_days_death\": \"Int64\", #Int64 (accepts NA) not int64\n",
    "          #\"wave_1\": \"category\", Removed no vacc available\n",
    "          #\"wave_2\": \"category\", Removed no vacc available\n",
    "          \"wave_3\": \"category\",\n",
    "          \"wave_4\": \"category\",\n",
    "          \"wave_5\": \"category\",\n",
    "          \"wave_6\": \"category\",\n",
    "          \"wave_7\": \"category\",\n",
    "          \"pmhx_activecancer\": \"category\",\n",
    "          \"pmhx_asthma\": \"category\",\n",
    "          \"pmhx_chf\": \"category\",\n",
    "          \"pmhx_chronicliver\": \"category\",\n",
    "          \"pmhx_ckd\": \"category\",\n",
    "          \"pmhx_copd\": \"category\",\n",
    "          \"pmhx_dementia\": \"category\",\n",
    "          \"pmhx_diabetes\": \"category\",\n",
    "          \"pmhx_hld\": \"category\",\n",
    "          \"pmhx_htn\": \"category\",\n",
    "          \"pmhx_ihd\": \"category\",\n",
    "          \"pmhx_obesity\": \"category\",\n",
    "          \"pmhx_stroke\": \"category\",\n",
    "          }\n",
    "\n",
    "#perform the change\n",
    "df = df.astype(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a preliminary analysis with clinical experts, the variables `reinfected` are discarded because they have a very small n and do not show a significant improvement. In addition, the variables `province` and `center` are eliminated because they do not provide any value to the survival analysis. They will be stored in separate files to be presented as appendices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"reinfected\"], inplace=True)\n",
    "df_annexed = df.loc[:,[\"province\", \"center\"]]\n",
    "df.drop(columns=[\"province\", \"center\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a categorical column that indicate if the patient is vaccinated 14 days before the admission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vaccinated\"] = df[\"num_shots\"].apply(lambda x: 1 if x > 0 else 0).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df.info(), end='\\n\\n')\n",
    "print(df_annexed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reorder the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['id', 'sex', 'age', 'num_shots', \"type_center\", 'vaccinated', 'icu', 'inpatient_days',\n",
    "            'admission_datetime', 'discharge_datetime', 'hospital_outcome',\n",
    "            'death_datetime', 'delta_days_death', #'wave_1', 'wave_2', removed no vacc available\n",
    "            'wave_3','wave_4', 'wave_5', 'wave_6', 'wave_7', 'pmhx_activecancer','pmhx_asthma',\n",
    "            'pmhx_chf', 'pmhx_chronicliver', 'pmhx_ckd', 'pmhx_copd','pmhx_dementia', \n",
    "            'pmhx_diabetes', 'pmhx_hld', 'pmhx_htn', 'pmhx_ihd','pmhx_obesity', \n",
    "            'pmhx_stroke', 'lab_alt', 'lab_ast', 'lab_creatinine','lab_crp', \n",
    "            'lab_ddimer', 'lab_glucose', 'lab_hct', 'lab_hemoglobin','lab_inr', \n",
    "            'lab_ldh', 'lab_leukocyte', 'lab_lymphocyte','lab_lymphocyte_percentage', \n",
    "            'lab_mch', 'lab_mcv', 'lab_neutrophil','lab_neutrophil_percentage', \n",
    "            'lab_platelet', 'lab_potassium', 'lab_rbc','lab_sodium', 'lab_urea']\n",
    "\n",
    "df = df[new_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save corrected dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./data/\" + os.path.basename(path)\n",
    "\n",
    "df.to_pickle(save_path)\n",
    "df_annexed.to_pickle('./data/geocount_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
